{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#install tweepy for streaming\n",
    "#! pip install tweepy\n",
    "\n",
    "#install and set up google.cloud for translation\n",
    "#!pip install google.cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Stream tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import SQLContext\n",
    "from time import gmtime, strftime\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "import numpy as np \n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib import style\n",
    "from pyspark.sql import Row\n",
    "import argparse\n",
    "from google.cloud import translate\n",
    "import six\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "import pytz\n",
    "from datetime import datetime\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import (VectorAssembler,VectorIndexer,\n",
    "OneHotEncoder,StringIndexer)\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#ensure spark context is running\n",
    "sc.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#ensure sql context is running\n",
    "sqlContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Lazily instantiated global instance of SQLContext\n",
    "def getSqlContextInstance(sparkContext):\n",
    "    if ('sqlContextSingletonInstance' not in globals()):\n",
    "        globals()['sqlContextSingletonInstance'] = SparkSession.builder.master(\"local[*]\")\\\n",
    "        .appName(\"appName\").config(\"spark.sql.warehouse.dir\", \"./spark-warehouse\").getOrCreate()\n",
    "    return globals()['sqlContextSingletonInstance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#initiate the streaming context\n",
    "ssc = StreamingContext(sc, 10 )\n",
    "\n",
    "#set the socket stream to connect to the tweetread file using the machine and port number\n",
    "socket_stream = ssc.socketTextStream(\"127.0.0.1\", 5555)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#set the batch window\n",
    "lines = socket_stream.window( 20 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#create a function to convert tweet time into easter time zone\n",
    "def get_time_zone():\n",
    "    tz = pytz.timezone('US/Eastern')\n",
    "    est_now = datetime.now(tz)\n",
    "    est=est_now.strftime('%Y-%m-%d %H:%M')\n",
    "    return est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#call the above functions on each Dstream of the rdd to map each tweet, set time zone, and write into a hive table\n",
    "( lines.map( lambda word: ( word.lower(), 1 ) ) \n",
    "  .map( lambda r: Row(tweet=r[0], timeTweet = get_time_zone() ))\n",
    "  .foreachRDD(lambda rdd: rdd.toDF().write.mode(\"append\").saveAsTable(\"tweets\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#initialize the streaming by calling the tweepy over the designated port\n",
    "ssc.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Stock Market Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from urllib2 import Request, urlopen\n",
    "import json\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import time\n",
    "from time import sleep\n",
    "\n",
    "request=Request(\"https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY&symbol=AAPL&interval=1min&apikey=GE5WPJIU1LE7WVC8\")\n",
    "response = urlopen(request)\n",
    "elevations = response.read()\n",
    "data = json.loads(elevations)\n",
    "final_data = pd.DataFrame(json_normalize(data).T)\n",
    "\n",
    "\n",
    "#retrieve stock data through url request\n",
    "for i in range(121):\n",
    "    request=Request(\"\"\"https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY&symbol\n",
    "                    =AAPL&interval=1min&apikey=GE5WPJIU1LE7WVC8\"\"\")\n",
    "    response = urlopen(request)\n",
    "    elevations = response.read()\n",
    "    data = json.loads(elevations)\n",
    "    data_frame = pd.DataFrame(json_normalize(data).T)\n",
    "    \n",
    "    frames = [final_data, data_frame]\n",
    "    final_data = pd.concat(frames)\n",
    "    print str(i)\n",
    "    #set timer to get one price every minute\n",
    "    time.sleep(60)\n",
    "\n",
    "#format dataframe\n",
    "stock_data=final_data.iloc[6:]\n",
    "stock_data.columns = ['close']\n",
    "stock_data.index.name = 'timeTweet'\n",
    "stock_data.reset_index(inplace=True)\n",
    "stock_data=stock_data[stock_data['timeTweet'].str.contains(\"close\")]\n",
    "stock_data['timeTweet']=stock_data['timeTweet'].str[19:35]\n",
    "stock_data['timeTweet']=pd.to_datetime(stock_data['timeTweet'],infer_datetime_format=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Check Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sqlContext.sql(\"show tables\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#check table format\n",
    "sqlContext.sql(\"select * from tweets limit 10\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#check tweet count\n",
    "sqlContext.sql(\"select count(*) from tweets\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#sqlContext.sql(\"drop table tweets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Translate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def translate_text(text):\n",
    "    \"\"\"Translates text into the target language.\n",
    "\n",
    "    Target must be an ISO 639-1 language code.\n",
    "    See https://g.co/cloud/translate/v2/translate-reference#supported_languages\n",
    "    \"\"\"\n",
    "    translate_client = translate.Client()\n",
    "\n",
    "    if isinstance(text, six.binary_type):\n",
    "        try:\n",
    "            text = text.decode(\"utf-8\")\n",
    "            result = translate_client.translate(text, target_language=\"en\")\n",
    "            output = result['translatedText']\n",
    "        except: \n",
    "            output = \"error\"\n",
    "    else:\n",
    "        result = translate_client.translate(text, target_language=\"en\")\n",
    "        output = result['translatedText']\n",
    "    time.sleep(1)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Calculate Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#read in the positive and negative word lists\n",
    "positive_words = Series(np.loadtxt('positive_words.txt',dtype = np.str))\n",
    "negative_words = Series(np.loadtxt('negative_words.txt',dtype = np.str))\n",
    "\n",
    "#pass a dataframe to the sentiment function to return the dataframe with two new columns\n",
    "def sentiment(sent):\n",
    "    sent['positive'] = 0.0\n",
    "    sent['negative'] = 0.0\n",
    "    \n",
    "    #sent each tweet to translator\n",
    "    sent[\"translation\"] = sent.tweet.apply(lambda tweet: translate_text(tweet))\n",
    "    sent['words'] = sent['translation'].str.split(' ')\n",
    "\n",
    "    for row in range(1,len(sent)):\n",
    "        word_count = 0\n",
    "        word_count += len(sent['words'][row])\n",
    "    \n",
    "        list_of_words = sent['words'][row]\n",
    "\n",
    "        positive_count = (positive_words.str.lower().isin(list_of_words)).sum()\n",
    "        negative_count = (negative_words.str.lower().isin(list_of_words)).sum()\n",
    "\n",
    "        positive_sent = (positive_count/float(word_count)).round(3)\n",
    "        negative_sent = (negative_count/float(word_count)).round(3)\n",
    "        \n",
    "        sent['positive'][row] = positive_sent\n",
    "        sent['negative'][row] = negative_sent\n",
    "\n",
    "\n",
    "    return sent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#call the sentiment function, which inherently calls the translation function\n",
    "sent = sentiment(sqlContext.sql(\"select * from tweets\").toPandas())\n",
    "\n",
    "sent['timeTweet']=pd.to_datetime(sent['timeTweet'],infer_datetime_format=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#transform the dataframe with tweets to a minute level and display each tweet in a new column \n",
    "groupedpositive= sent.groupby('timeTweet')['positive'].apply(lambda df: df.reset_index(drop=True)).unstack()\n",
    "groupednegative= sent.groupby('timeTweet')['negative'].apply(lambda df: df.reset_index(drop=True)).unstack()\n",
    "\n",
    "groupednegative=groupednegative.ix[:,0:15]\n",
    "groupedpositive=groupedpositive.ix[:,0:15]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#use matplotlib animation to display a frame by frame minute analysis of the tweet sentiment\n",
    "%matplotlib notebook\n",
    "\n",
    "matrixNegative = np.matrix(groupedpositive.transpose())\n",
    "matrixPositive = np.matrix(groupednegative.transpose())\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.ion()\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Sentiment\")\n",
    "plt.title(\"Sentiment by Minute\")\n",
    "\n",
    "fig.show()\n",
    "fig.canvas.draw()\n",
    "\n",
    "for i in range(0,len(groupedpositive)):\n",
    "    time.sleep(.5)\n",
    "    ax.clear()\n",
    "    ax.plot(matrixPositive[:,i])\n",
    "    ax.plot(matrixNegative[:,i])\n",
    "    ax.text(.8,1.1, \"Blue = Positive\", transform=ax.transAxes)\n",
    "    ax.text(.8,1.05, \"Orange = Negative\", transform=ax.transAxes)\n",
    "    fig.suptitle(\"Sentiment by Minute\")\n",
    "    ax.text(.45,-.10, \"Tweet\", transform=ax.transAxes)\n",
    "    ax.text(-.16,0, \"Sentiment\", transform=ax.transAxes)\n",
    "    fig.canvas.draw()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Have only the required variables in the dataframe for regression\n",
    "stock_sentiment_lm = stock_sentiment[['positive','negative','close']]\n",
    "\n",
    "#Remove NAs\n",
    "stock_sentiment_lm=stock_sentiment_lm.fillna(0)\n",
    "\n",
    "#Convert all the values to float so that spark will read it as double\n",
    "stock_sentiment_lm['close']=stock_sentiment_lm['close'].astype('float64', raise_on_error = False)\n",
    "stock_sentiment_lm['positive']=stock_sentiment_lm['positive'].astype('float64', raise_on_error = False)\n",
    "stock_sentiment_lm['negative']=stock_sentiment_lm['negative'].astype('float64', raise_on_error = False)\n",
    "\n",
    "\n",
    "#Converting pandas dataframe to spark dataframe\n",
    "stock_sent_lm_df=sqlContext.createDataFrame(stock_sentiment_lm)\n",
    "#Checking the data\n",
    "stock_sent_lm_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Transform all features into a vector using VectorAssembler\n",
    "assemblerInputs = [\"positive\", \"negative\"]\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "output = assembler.transform(stock_sent_lm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Only keep the label and the feature\n",
    "df = output.selectExpr( \"features\",\"close as label\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define LinearRegression algorithm\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Fitting the model\n",
    "lm_model = lr.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Evaluating the coefficients\n",
    "\n",
    "summary = lm_model.summary\n",
    "print(\"Coefficient Standard Errors: \" + str(summary.coefficientStandardErrors))\n",
    "print(\"T Values: \" + str(summary.tValues))\n",
    "print(\"P Values: \" + str(summary.pValues))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
